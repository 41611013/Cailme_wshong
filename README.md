# CAIL2018

该项目为 **CAIL2018** 的代码和模型提交说明。

## 选手交流群

QQ群：237633234

## 提交的文件格式及组织形式

你可以在 ``python_sample`` 中找到最简单的提交代码的格式。你需要将你所有的代码压缩为一个 ``zip`` 文件进行提交，该 ``zip`` 文件内部形式可以参看 ``python_smaple/predictor.zip``。该 ``zip`` 文件内部顶层应该只包含一个叫做 ``predictor`` 的文件夹，在该文件夹下需要有你的所有代码、模型及其他相关的东西。

在压缩包内的 ``predictor`` 文件夹内，你需要保证 ``__init__.py`` 和 ``predictor.py`` 这两个文件一定存在。这两个文件的内容我们将在下文提及。

## 代码的内容

你需要保证 ``__init__.py`` 在文件夹 ``predictor`` 内存在并且内容为：

```from .predictor import Predictor```

你需要保证 ``predictor.py`` 在文件夹 ``predictor`` 内存在，并且其中实现了 ``Predictor`` 这个类。``Predictor`` 类需要实现如下几个函数：

* ``__init__``：你需要在该函数类中完成你模型的各种初始化，并且为该类声明变量 ``batch_size``，该变量代表评测器每次需要给你多少个数据同时进行预测。``batch_size`` 需要是一个大于等于 $1$ 的整数，如果该参数对你来说没有意义，请直接使用 ``self.batch_size=1`` 将该变量设为 $1$。
* ``predict(content)``：在该函数内你需要实现自动判决的预测。参数 ``content`` 为一个长度**不超过** ``batch_size`` 的数组，其中每个元素为一个字符串，对应下载的数据中的事实即 ``fact`` 字段，你需要对每一个数组中的元素进行预测，并返回预测的结果 ``result``。``result``的类型应该为数组，且其元素个数应与 ``content`` 的元素个数相同，并且 ``result`` 中预测的结果顺序应与 ``content`` 中的事实顺序相同。对于每个预测结果，其类型应为 ``dict`` 类型，且包含以下字段：
    * ``accusation``：该字段的类型为一个数组，数组中包含若干个整数，代表预测相关罪名的结果。如 $[1,2,3]$ 表示和第 $1,2,3$ 条罪名都相关，罪名的编号与下发的 ``accu.txt`` 中的顺序一致，从 $1$ 开始编号。
    * ``articles``：该字段的类型为一个数组，数组中包含若干个整数，代表预测相关法条的结果。如 $[1,2,3]$ 表示和第 $1,2,3$ 条法条都相关，法条的编号与下发的 ``law.txt`` 中的顺序一致，从 $1$ 开始编号。**注意**这里的数字并不是代表你预测的结果为法条的第几条，你预测的结果为 $1$ 代表的是 ``law.txt`` 中的第一条法条。
    * ``imprisonment``：该字段类型为一个整数，代表预测的刑期，单位为月。如果预测结果为无期徒刑，请将该字段的值设为 $-1$；如果预测结果为死刑，请将该字段的值设为 $-2$。

以上为 ``predictor.py`` 中你需要实现的内容，你可以利用 ``python_example/predictor`` 下的文件进行进一步参考。**请注意**，代码运行的目录并不是在predictor目录下，而是在predictor的上一级目录，所以请在加载模型的时候尽量使用关于``predictor.py``的相对路径。

## 其他语言的支持

如上文所述，我们现阶段只支持 ``python`` 语言的提交，但是这并不代表你不能够使用其他语言进行预测。我们在 ``c++_sample/predictor`` 下提供了一种可能的 ``c++`` 的实现方法。我们现在仍然需要实现上文所述的 ``predictor.py`` 的各种接口，但是我们在预测的时候利用 ``os.system`` 调用系统命令运行你编译好的可执行文件，或者其他运行你代码的命令。如果你担心可执行文件没有权限，可以像给出的例子在初始化的过程中加上权限。

## 评测脚本

我们在 ``judger`` 文件夹中提供了一个 ``Judger`` 的类可以帮助你计算你三个任务的得分，你可以参考该代码实现你自己的Judger。该Judger所使用的读入格式仅用于我们的评测，如果你需要使用该代码，请根据你的需求自行进行修改。


## 个人修改部分！！！！！
## 文本预处理，分词、去停用词、正则去时间，在文件夹text_pre_process下。
采用哈工大的pylpt，去除fact第一句，去除时间，比如2018年5月29日，去掉停用词。
用train、test、valid 的fact部分 Keras.Tokenizer, 取词频前20000个词，做成词典，后续只要读词典就行，不需要load所有的词向量。
将train、test、valid 的fact部分 全部转换成数字序列，数字代表该词在字典的位置，通过字典取向量就行了。
## 模型
CNN_base_model:基于卷积神经网络
